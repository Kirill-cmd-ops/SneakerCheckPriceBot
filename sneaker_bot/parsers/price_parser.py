import os
import re
import aiohttp
import asyncio
import random
from urllib.parse import urljoin
from bs4 import BeautifulSoup
from dotenv import load_dotenv

from aiogram import Router
from aiogram.exceptions import TelegramBadRequest
from aiogram.fsm.context import FSMContext
from aiogram.types import CallbackQuery, Message

from sneaker_bot.menu.know_menu import know_menu
from sneaker_bot.services.build_text_parser_price import build_result_text
from sneaker_bot.services.send_messages import record_and_send, send_prompt
from sneaker_bot.tasks import tasks

load_dotenv()
router = Router()

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è ---
HEADERS = {"User-Agent": os.getenv("USER_AGENT", "Mozilla/5.0")}
PER_CAT = int(os.getenv("PER_CAT", 5))
BASE = os.getenv("BASE_URL", "")
CATALOGS = [
    urljoin(BASE, os.getenv("CATALOG_MEN_PATH", "")),
    urljoin(BASE, os.getenv("CATALOG_WOMEN_PATH", "")),
]
SNEAKERS = {
    "–∂–µ–Ω—Å–∫–∏–µ": os.getenv("SNEAKERS_WOMEN_URL", ""),
    "–º—É–∂—Å–∫–∏–µ": os.getenv("SNEAKERS_MEN_URL", ""),
}
MAX_PAGES_BUNT = int(os.getenv("MAX_PAGES_BUNT", 1))
MAX_PAGES_SNEAK = int(os.getenv("MAX_PAGES_SNEAK", 1))

SUCCESS_STICKERS = [
    "CAACAgIAAxkBAAEQAAE2aT7hurip0DwMapzkZIF1TGG5hqUAAqIBAAIWQmsKoXd3Y5pOgyE2BA",
]
FAIL_STICKERS = [
    "CAACAgIAAxkBAAEQAAE6aT7ixzphsIWAPUf6O9gnwMdsOdIAArEBAAIWQmsK_Er0l4LrkDE2BA",
]


# -----------------------
# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º (prompt_refs, msg_refs, sticker_info)
# -----------------------
async def delete_last_prompt_on_reply(state: FSMContext, bot, chat_id: int) -> bool:
    """
    –£–¥–∞–ª—è–µ—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é –ø–æ–¥—Å–∫–∞–∑–∫—É –∏–∑ state['prompt_refs'].
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ—à–ª–æ —É—Å–ø–µ—à–Ω–æ, False –∏–Ω–∞—á–µ.
    """
    data = await state.get_data()
    prompts = data.get("prompt_refs", [])
    if not prompts:
        return False

    last = prompts.pop()  # —É–¥–∞–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π prompt
    await state.update_data(prompt_refs=prompts)

    try:
        await bot.delete_message(chat_id=last["chat_id"], message_id=last["message_id"])
        print("Deleted prompt:", last)
        return True
    except Exception as e:
        print("Failed to delete prompt:", last, e)
        return False


async def save_sticker_info(state: FSMContext, sticker_msg: Message):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∏–∫–µ—Ä–µ –≤ state –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è –ø–æ back."""
    await state.update_data(sticker_info={"chat_id": sticker_msg.chat.id, "message_id": sticker_msg.message_id})


async def delete_all_prompts_and_sticker(state: FSMContext, bot):
    """
    –£–¥–∞–ª—è–µ—Ç –≤—Å–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ prompt_refs –∏ —Å—Ç–∏–∫–µ—Ä (sticker_info).
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–∏ –Ω–∞–∂–∞—Ç–∏–∏ –∫–Ω–æ–ø–∫–∏ 'back' –∏–ª–∏ –ø—Ä–∏ —è–≤–Ω–æ–π –æ—á–∏—Å—Ç–∫–µ.
    """
    data = await state.get_data()
    prompts = data.get("prompt_refs", [])
    sticker_info = data.get("sticker_info")

    for ref in prompts:
        try:
            await bot.delete_message(chat_id=ref["chat_id"], message_id=ref["message_id"])
            print("Deleted prompt:", ref)
        except Exception as e:
            print("Failed to delete prompt:", ref, e)

    if sticker_info:
        try:
            await bot.delete_message(chat_id=sticker_info["chat_id"], message_id=sticker_info["message_id"])
            print("Deleted sticker:", sticker_info)
        except Exception as e:
            print("Failed to delete sticker:", sticker_info, e)

    await state.update_data(prompt_refs=[])
    await state.update_data(sticker_info=None)


# -----------------------
# –ü–∞—Ä—Å–∏–Ω–≥ (—É—Å—Ç–æ–π—á–∏–≤—ã–π)
# -----------------------
def normalize_price(text: str) -> str:
    if not text:
        return "‚Äî"
    m = re.search(r"(\d[\d\s.,]+)\s*(BYN|‚ÇΩ|RUB|USD|‚Ç¨)?", text, flags=re.IGNORECASE)
    if not m:
        return "‚Äî"
    amount = m.group(1).replace(",", ".").strip()
    currency = (m.group(2) or "").upper().replace("RUB", "‚ÇΩ")
    return f"{amount} {currency}".strip()


def extract_price(ds: BeautifulSoup) -> str:
    selectors = [
        "p.price",
        "span.price",
        "div.price",
        "div.product-price",
        "span.woocommerce-Price-amount",
        "ins .woocommerce-Price-amount",
        "meta[itemprop='price']",
        "[data-price]",
        "span[class*='cost']",
        "div[class*='price']",
    ]
    for sel in selectors:
        el = ds.select_one(sel)
        if not el:
            continue
        if el.name == "meta":
            return normalize_price(el.get("content", "").strip())
        if el.has_attr("data-price"):
            return normalize_price(el["data-price"])
        txt = el.get_text(" ", strip=True)
        price = normalize_price(txt)
        if price != "‚Äî":
            return price
    return normalize_price(ds.get_text(" ", strip=True))


def find_title_and_link(card, base: str):
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏—è –∏ —Å—Å—ã–ª–∫–∏:
    1) —è–≤–Ω—ã–µ <a> —Å —Ç–µ–∫—Å—Ç–æ–º;
    2) img@alt;
    3) title/aria-label;
    4) h1/h2/h3/strong;
    5) data-* –∞—Ç—Ä–∏–±—É—Ç—ã.
    """
    # 1) —è–≤–Ω—ã–µ —Å—Å—ã–ª–∫–∏ —Å –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
    for a in card.find_all("a", href=True):
        text = a.get_text(" ", strip=True)
        if text and len(text) >= 3 and not re.fullmatch(r"[\d\s\-]+", text):
            href = a["href"]
            full = urljoin(base, href)
            return text, full

    # 2) img alt
    img = card.find("img", alt=True)
    if img:
        alt = img.get("alt", "").strip()
        if alt and len(alt) >= 3 and not re.fullmatch(r"[\d\s\-]+", alt):
            parent_a = img.find_parent("a", href=True)
            href = parent_a["href"] if parent_a else img.get("data-src") or img.get("src")
            full = urljoin(base, href) if href else base
            return alt, full

    # 3) title / aria-label
    for el in (card.find_all(attrs={"title": True}) + card.find_all(attrs={"aria-label": True})):
        txt = el.get("title") or el.get("aria-label")
        if txt and len(txt.strip()) >= 3 and not re.fullmatch(r"[\d\s\-]+", txt.strip()):
            href = el.get("href") or el.get("data-href") or None
            full = urljoin(base, href) if href else base
            return txt.strip(), full

    # 4) –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤–Ω—É—Ç—Ä–∏ –∫–∞—Ä—Ç–æ—á–∫–∏
    for tag in ("h1", "h2", "h3", "h4", "strong"):
        h = card.select_one(tag)
        if h:
            txt = h.get_text(" ", strip=True)
            if txt and len(txt) >= 3 and not re.fullmatch(r"[\d\s\-]+", txt):
                a = h.find_parent().find("a", href=True) if h.find_parent() else None
                href = a["href"] if a else None
                full = urljoin(base, href) if href else base
                return txt, full

    # 5) data-* –∞—Ç—Ä–∏–±—É—Ç—ã
    for attr in ("data-name", "data-title", "data-product-name"):
        if card.has_attr(attr):
            txt = card[attr].strip()
            if txt and len(txt) >= 3:
                href = card.get("data-href") or card.get("data-url") or None
                full = urljoin(base, href) if href else base
                return txt, full

    return None


async def fetch_html(session: aiohttp.ClientSession, url: str) -> BeautifulSoup | None:
    try:
        r = await session.get(url, timeout=20, allow_redirects=True)
        if r.status != 200:
            print(f"HTTP {r.status} for {url}")
            return None
        html = await r.text()
        return BeautifulSoup(html, "lxml")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ {url}: {e}")
        return None


# -----------------------
# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ —Ü–µ–Ω
# -----------------------
async def process_price_search(user_id: int, query_ctx: CallbackQuery, state: FSMContext, q: str):
    try:
        temp_to_delete: list[dict] = []

        load_msg = await record_and_send(query_ctx, state, text="–ò—â–µ–º —É–∫–∞–∑–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∫—Ä–æ—Å—Å–æ–≤–æ–∫ –∏ —Å—Ö–æ–∂–∏–µ –º–æ–¥–µ–ª–∏‚Ä¶")
        temp_to_delete.append({"chat_id": load_msg.chat.id, "message_id": load_msg.message_id})

        raw_bunt = {"muzhskie": [], "zhenskie": []}
        raw_sneaker = {"–∂–µ–Ω—Å–∫–∏–µ": [], "–º—É–∂—Å–∫–∏–µ": []}

        async with aiohttp.ClientSession(headers=HEADERS) as session:
            # bunt.by
            for url in CATALOGS:
                if not url.strip():
                    continue
                key = "muzhskie" if "muzh" in url.lower() else "zhenskie"
                soup = await fetch_html(session, url)
                if soup is None:
                    continue

                cards = soup.select("div[class*='product'], li[class*='product'], article[class*='product']")
                if not cards:
                    cards = soup.select("div, li, article")

                print(f"bunt.by: –Ω–∞–π–¥–µ–Ω–æ {len(cards)} –∫–∞—Ä—Ç–æ—á–µ–∫ –Ω–∞ {url}")

                # –æ—Ç–ª–∞–¥–∫–∞: –ø—Ä–µ–≤—å—é –ø–µ—Ä–≤–æ–π –∫–∞—Ä—Ç–æ—á–∫–∏
                if cards:
                    try:
                        print("=== –ü—Ä–µ–≤—å—é –ø–µ—Ä–≤–æ–π –∫–∞—Ä—Ç–æ—á–∫–∏ (bunt.by) ===")
                        print(cards[0].prettify()[:1000])
                        print("=== –ö–æ–Ω–µ—Ü –ø—Ä–µ–≤—å—é ===")
                    except Exception:
                        pass

                found_preview = 0
                for card in cards:
                    res = find_title_and_link(card, BASE or url)
                    if not res:
                        continue
                    t, full = res
                    if found_preview < 5:
                        print(f"[bunt.by] title: {t} | url: {full}")
                        found_preview += 1
                    if q and q.strip():
                        if q.lower() not in t.lower():
                            continue
                    raw_bunt[key].append((t, full))
                    if len(raw_bunt[key]) >= PER_CAT:
                        break

                # –ø–∞–≥–∏–Ω–∞—Ü–∏—è bunt.by
                for p in range(2, MAX_PAGES_BUNT + 1):
                    if len(raw_bunt[key]) >= PER_CAT:
                        break
                    next_url = urljoin(url, f"/page/{p}/")
                    sp = await fetch_html(session, next_url)
                    if sp is None:
                        break
                    cards_p = sp.select("div[class*='product'], li[class*='product'], article[class*='product']")
                    if not cards_p:
                        cards_p = sp.select("div, li, article")
                    for card in cards_p:
                        res = find_title_and_link(card, BASE or url)
                        if not res:
                            continue
                        t, full = res
                        if q and q.strip():
                            if q.lower() not in t.lower():
                                continue
                        raw_bunt[key].append((t, full))
                        if len(raw_bunt[key]) >= PER_CAT:
                            break

            # sneakers.by –ø–∞—Ä—Å–∏–Ω–≥
            for kind, base in SNEAKERS.items():
                if not base.strip():
                    continue
                for p in range(1, MAX_PAGES_SNEAK + 1):
                    page_url = base if p == 1 else f"{base}?page={p}"
                    soup = await fetch_html(session, page_url)
                    if soup is None:
                        break
                    cards = soup.select("div[class*='product'], li[class*='product'], article[class*='product']")
                    if not cards:
                        cards = soup.select("div, li, article")
                    print(f"sneakers.by: –Ω–∞–π–¥–µ–Ω–æ {len(cards)} –∫–∞—Ä—Ç–æ—á–µ–∫ –Ω–∞ {page_url}")
                    found_preview = 0
                    for card in cards:
                        res = find_title_and_link(card, BASE or base)
                        if not res:
                            continue
                        t, full = res
                        if found_preview < 5:
                            print(f"[sneakers.by] title: {t} | url: {full}")
                            found_preview += 1
                        if q and q.strip():
                            if q.lower() not in t.lower():
                                continue
                        raw_sneaker[kind].append((t, full))
                        if len(raw_sneaker[kind]) >= PER_CAT:
                            break
                    if len(raw_sneaker[kind]) >= PER_CAT:
                        break

            async def price_b(item):
                t, u = item
                try:
                    rr = await session.get(u, timeout=20)
                    rr.raise_for_status()
                    ds = BeautifulSoup(await rr.text(), "lxml")
                    price = extract_price(ds)
                    return t, price if price else "‚Äî", u
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ü–µ–Ω—ã bunt.by: {e} | url: {u}")
                    return t, "–æ—à–∏–±–∫–∞", u

            async def price_s(item):
                t, u = item
                try:
                    rr = await session.get(u, timeout=20)
                    rr.raise_for_status()
                    ds = BeautifulSoup(await rr.text(), "lxml")
                    price = extract_price(ds)
                    return t, price if price else "‚Äî", u
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ü–µ–Ω—ã sneakers.by: {e} | url: {u}")
                    return t, "–æ—à–∏–±–∫–∞", u

            fb = {k: await asyncio.gather(*[price_b(i) for i in v]) for k, v in raw_bunt.items()}
            fs = {k: await asyncio.gather(*[price_s(i) for i in v]) for k, v in raw_sneaker.items()}

        text = build_result_text(fb, fs)

        no_results = (
            text.strip() == "" or
            (all(len(v) == 0 for v in fb.values()) and all(len(v) == 0 for v in fs.values()))
        )

        # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ –≤ state (—á—Ç–æ–±—ã —É–¥–∞–ª–∏—Ç—å –ø–æ–∑–∂–µ –ø–æ back)
        sticker_id = random.choice(FAIL_STICKERS if no_results else SUCCESS_STICKERS)
        sticker_msg = await query_ctx.bot.send_sticker(chat_id=query_ctx.from_user.id, sticker=sticker_id)
        await save_sticker_info(state, sticker_msg)

        # –∏—Ç–æ–≥–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ record_and_send (–æ–Ω–æ –ø–æ–ø–∞–¥—ë—Ç –≤ state['msg_refs'])
        if no_results:
            await record_and_send(query_ctx, state, text="–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ üòî", reply_markup=know_menu)
        else:
            await record_and_send(query_ctx, state, text=text, reply_markup=know_menu, disable_web_page_preview=True)

        # —É–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä load_msg)
        for m in temp_to_delete:
            try:
                await query_ctx.bot.delete_message(chat_id=m["chat_id"], message_id=m["message_id"])
            except TelegramBadRequest:
                pass

    except asyncio.CancelledError:
        return
    finally:
        tasks.pop(user_id, None)


# -----------------------
# –ü—Ä–∏–º–µ—Ä—ã —Ö—ç–Ω–¥–ª–µ—Ä–æ–≤ –≤–≤–æ–¥–∞ (–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è delete_last_prompt_on_reply + send_prompt)
# -----------------------
# –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: —ç—Ç–∏ –ø—Ä–∏–º–µ—Ä—ã –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ. –ü–æ–¥—Å—Ç–∞–≤—å —Å–≤–æ–∏ —Ñ–∏–ª—å—Ç—Ä—ã/—Å–æ—Å—Ç–æ—è–Ω–∏—è.

@router.message(lambda m: m.text and m.text.lower() == "start_brand")
async def ask_brand(message: Message, state: FSMContext):
    # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–¥—Å–∫–∞–∑–∫—É —á–µ—Ä–µ–∑ send_prompt ‚Äî –æ–Ω–∞ –ø–æ–ø–∞–¥—ë—Ç –≤ state['prompt_refs']
    await send_prompt(message, state, "–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –±—Ä–µ–Ω–¥–∞")


@router.message(lambda m: m.text and m.text.strip() != "")
async def brand_received(message: Message, state: FSMContext):
    # —É–¥–∞–ª—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –ø–æ–¥—Å–∫–∞–∑–∫—É (—Ç–æ—Ç —Å–∞–º—ã–π "–í–≤–µ–¥–∏—Ç–µ –±—Ä–µ–Ω–¥")
    await delete_last_prompt_on_reply(state, message.bot, message.chat.id)

    brand = message.text.strip()
    await state.update_data(brand=brand)

    # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–ª–µ–¥—É—é—â—É—é –ø–æ–¥—Å–∫–∞–∑–∫—É —á–µ—Ä–µ–∑ send_prompt
    await send_prompt(message, state, "–í–≤–µ–¥–∏—Ç–µ –º–æ–¥–µ–ª—å")


@router.message(lambda m: m.text and m.text.strip() != "")
async def model_received(message: Message, state: FSMContext):
    # —É–¥–∞–ª—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –ø–æ–¥—Å–∫–∞–∑–∫—É "–í–≤–µ–¥–∏—Ç–µ –º–æ–¥–µ–ª—å"
    await delete_last_prompt_on_reply(state, message.bot, message.chat.id)

    model = message.text.strip()
    await state.update_data(model=model)

    # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–¥—Å–∫–∞–∑–∫—É –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞
    await send_prompt(message, state, "–í–≤–µ–¥–∏—Ç–µ —Ä–∞–∑–º–µ—Ä")


@router.message(lambda m: m.text and m.text.strip() != "")
async def size_received(message: Message, state: FSMContext):
    # —É–¥–∞–ª—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –ø–æ–¥—Å–∫–∞–∑–∫—É "–í–≤–µ–¥–∏—Ç–µ —Ä–∞–∑–º–µ—Ä"
    await delete_last_prompt_on_reply(state, message.bot, message.chat.id)

    size = message.text.strip()
    await state.update_data(size=size)

    # —Å–æ–±–∏—Ä–∞–µ–º –∑–∞–ø—Ä–æ—Å –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫ (–ø—Ä–∏–º–µ—Ä)
    data = await state.get_data()
    query = " ".join(filter(None, [data.get("brand"), data.get("model"), data.get("size")]))
    await record_and_send(message, state, f"–ó–∞–ø—É—Å–∫–∞—é –ø–æ–∏—Å–∫ –ø–æ: {query}")

    # –ï—Å–ª–∏ —É —Ç–µ–±—è –µ—Å—Ç—å CallbackQuery –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è process_price_search, –∞–¥–∞–ø—Ç–∏—Ä—É–π –≤—ã–∑–æ–≤.
    # –ó–¥–µ—Å—å –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è: –º–æ–∂–Ω–æ –≤—ã–∑–≤–∞—Ç—å process_price_search —á–µ—Ä–µ–∑ –∏–º–∏—Ç–∞—Ü–∏—é CallbackQuery,
    # –ª–∏–±–æ –≤—ã–Ω–µ—Å—Ç–∏ –ª–æ–≥–∏–∫—É –ø–æ–∏—Å–∫–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é, –ø—Ä–∏–Ω–∏–º–∞—é—â—É—é chat_id –∏ state.
